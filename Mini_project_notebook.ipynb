{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will first import all the libraries and functions we will need\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a231ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                \n",
    "import re                                 \n",
    "import string                             \n",
    "import numpy as np\n",
    "import pandas as pd                         \n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "from os.path import exists\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function will clean all the text data in the pandas data frame that is passed to it \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54adfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(unclean): \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, # Initializing the tokenizer from nltk\n",
    "                                reduce_len=True)\n",
    "    stopwords_english = stopwords.words('english') #importing english stopwords \n",
    "    stemmer = PorterStemmer() #Initializing the stemmer class \n",
    "    clean_text = []\n",
    "    clean_stem_text = [] \n",
    "\n",
    "    # remove stock market tickers like $GE\n",
    "    unclean = re.sub(r'\\$\\w*', '', unclean)\n",
    "    # Remove old style retweet text \"RT\"\n",
    "    unclean = re.sub(r'^RT[\\s]+', '', unclean)\n",
    "    # Remove \\n characters \n",
    "    unclean = unclean.strip()\n",
    "    # Remove hyperlinks\n",
    "    unclean = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', unclean)\n",
    "    # Remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    unclean = re.sub(r'#', '', unclean)\n",
    "    # Tokenizing\n",
    "    unclean = tokenizer.tokenize(unclean)\n",
    "    for word in unclean: # Go through every word in your tokens list\n",
    "        if (word not in stopwords_english and  word not in string.punctuation):  # remove punctuation and stopwords\n",
    "            clean_text.append(word)\n",
    "\n",
    "    for word in clean_text:\n",
    "        stem_word = stemmer.stem(word)  # stemming word\n",
    "        clean_stem_text.append(stem_word)  # append to the list\n",
    "\n",
    "    return clean_stem_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6237706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this function we check that there is no cleaned data already otherwise \n",
    "we just use it and avoid wasting time and cleaning it again \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16834933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text():\n",
    "    if exists('clean_text_news.csv'): \n",
    "        return  pd.read_csv(r'clean_text_news.csv')\n",
    "    else: \n",
    "        df = pd.read_csv(r'news.csv')\n",
    "        df['text']=df['text'].apply(clean)\n",
    "        df['title']=df['title'].apply(clean)\n",
    "        df.to_csv('clean_text_news.csv', index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09021015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the Naïve Bayes Classifier model training testing and evaluation function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c169ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial (X_train_tf,X_test_tf, y_test, y_train): \n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train_tf, y_train)\n",
    "    y_pred = mnb.predict(X_test_tf)\n",
    "    mnb_score = accuracy_score(y_test, y_pred) \n",
    "    print(\"Naïve Bayes Classifier\")\n",
    "    print(\"Accuracy score is: \",mnb_score)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the logistic regression model training testing and evaluation function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b66d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train_tf,X_test_tf, y_test, y_train):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_tf, y_train)\n",
    "    y_pred = lr.predict(X_test_tf)\n",
    "    score = lr.score(X_test_tf, y_test)\n",
    "    print(\"Logistic regression\")\n",
    "    print(\"Accuracy score is: \",score)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the Support Vector Machines model training testing and evaluation function\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c7f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machines(X_train_tf,X_test_tf, y_test, y_train):\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "    clf.fit(X_train_tf, y_train)\n",
    "    y_pred = clf.predict(X_test_tf)\n",
    "    score = clf.score(X_test_tf, y_test)\n",
    "    print(\"Support Vector Machines\")\n",
    "    print(\"Accuracy score is: \",score)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70408ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the \"K-nearest-neighbors model training testing and evaluation function with k = 5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ad405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbour(X_train_tf,X_test_tf, y_test, y_train): \n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_tf, y_train)\n",
    "    y_pred = knn.predict(X_test_tf)\n",
    "    score = knn.score(X_test_tf, y_test)\n",
    "    print(\"K-nearest-neighbors with K = 5\")\n",
    "    print(\"Accuracy score is: \",score)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the Main function, we first split the data,  80% will be training while the remaining 20% will be the test data.\n",
    "The data will be randomized so each iterazion gives a different split with the same percentages.\n",
    "We then perform Features Extraction and test each of our model with the resulting train and test data we have.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0336be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Classifier\n",
      "Accuracy score is:  0.8366219415943172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.98      0.69      0.81       632\n",
      "        REAL       0.76      0.99      0.86       635\n",
      "\n",
      "    accuracy                           0.84      1267\n",
      "   macro avg       0.87      0.84      0.83      1267\n",
      "weighted avg       0.87      0.84      0.83      1267\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Logistic regression\n",
      "Accuracy score is:  0.9226519337016574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.90      0.95      0.92       632\n",
      "        REAL       0.95      0.90      0.92       635\n",
      "\n",
      "    accuracy                           0.92      1267\n",
      "   macro avg       0.92      0.92      0.92      1267\n",
      "weighted avg       0.92      0.92      0.92      1267\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Support Vector Machines\n",
      "Accuracy score is:  0.9384372533543804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.93      0.95      0.94       632\n",
      "        REAL       0.95      0.92      0.94       635\n",
      "\n",
      "    accuracy                           0.94      1267\n",
      "   macro avg       0.94      0.94      0.94      1267\n",
      "weighted avg       0.94      0.94      0.94      1267\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "K-nearest-neighbors with K = 5\n",
      "Accuracy score is:  0.6053670086819258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.56      1.00      0.72       632\n",
      "        REAL       0.99      0.22      0.35       635\n",
      "\n",
      "    accuracy                           0.61      1267\n",
      "   macro avg       0.77      0.61      0.53      1267\n",
      "weighted avg       0.77      0.61      0.53      1267\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_text()\n",
    "x = df['text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "tf_vectorizer = TfidfVectorizer(use_idf=True) \n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train)\n",
    "X_test_tf = tf_vectorizer.transform(X_test)\n",
    "multinomial(X_train_tf,X_test_tf, y_test, y_train)\n",
    "logistic_regression(X_train_tf,X_test_tf, y_test, y_train)\n",
    "support_vector_machines(X_train_tf,X_test_tf, y_test, y_train)\n",
    "k_neighbour(X_train_tf,X_test_tf, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2fcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
